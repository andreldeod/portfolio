---
title: "Final Project Overview: CAFOs in Yucatán"
author: "André Luiz de Oliveira Domingues and Clio Bate"
date: "2023-04-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
1. Summary: A brief (up to 250 words) description of the project, and a bullet point or enumerated list of its primary objectives.


Our final project will be focused on studying the growth of Concentrated Animal Feeding Operations (CAFOs) in Mexican's Yucatán peninsula. Industrial pig farming has been growing in Yucatán with adverse environmental and social impacts. Our project study area will consist of three communities in Yucatán: Sitilpech, Uayalceh, and Kinchil. We will develop a method for identifying CAFO's refuse lagoons from satellite imagery— as these lagoons will have a unique spectral signature compared to other bodies of water— identify when the lagoons began to appear in each community and at what scale and rate they have grown over time. Our project is intended to add to previous research on CAFOs in Yucatán and support community claims of increasing, illegal, industrial swine operations in their territories.  

-Use spectral signatures of known CAFO lagoons to train a Random Forest model to identify lagoons. 

-Use rgee package to access satellite imagery collections dating back to at least 1995. 

-Run the model on the time series of images to identify when the CAFOs started to appear in the three municipalities and track their growth in the region over time. 

-Represent the data in R with maps and graphs that show the growth and distribution of CAFOS in the three communities. 


--------------------------------------------------------------------------------

2. Approach and Method: An outline of the analytical methods and code you plan to use, including the names of key packages that you will draw on. This section should be composed of the following sub-sections:


Outline of Methods: 

Set up 

Set up a shared repo on GitHub and connect our RStudio. 

Install and set up the Google Earth Engine rgee package on both of our R Studios. The paths to the keys, authentication files, buckets, etc. must be changed manually each time we pull to our shared REPO on GitHub as each computer must have local paths in the .renv file that point to the location of the key, authentication files, buckets, and earth engine’s python, to be able to use the rgee package. The local paths must be saved in in a separate file in Rstudio which will be to copied and pasted into the .renv file.  

For example: 

GAR_CLIENT_JSON=C:/Rclass/json/client_secret_745019109141-ot7egdp6o4jgma17kjo1u5ca2m9ban6s.apps.googleusercontent.com.json 

GCS_AUTH_FILE=C:/Rclass/json/rclassspring2023-5ac20026c0aa.json 

GCS_DEFAULT_BUCKET=cafoprojectbucket 

EARTHENGINE_PYTHON="C:/Users/cvale/AppData/Local/r-miniconda/envs/rgee/python.exe" 

EARTHENGINE_ENV="C:/Users/cvale/AppData/Local/r-miniconda/envs/rgee" 

Processing: 

Download all shapefiles from Mike. These include: 

-Fabrica de cerdos: the main shapefile with all the factories, shapefiles and points 

municipalities 

Localidades_5km 

rastos certificados(TIF) - slaughter houses, small and large 

Select lagunas from the “fabricas” shapfile(this shapefile is a mix of the lagunas and the associated granjas), create a new layer, export that data to create a new shapefile, and save that in a shared folder for future analysis 

Using rgee, download Landsat satellite 9 imagery from google earth engine for the most recent, cloud-free/interference free date we can find. 

Take a random sample of 50 lagunas to compare to the most recent satellite imagery. Because many of the Lagunas are from different years (between 2000 and 2019) we want to visually ensure that there still are lagunas in our most current images before we start to train our data.  

For each year starting from 2019 and moving backwards to 1995.  

Download one cloud free images from Landsat 5(for images from 1995-1998, 2003-2011), Landsat 7(1999-2003), Landsat 8(2013-2021), Landsat 9(2021-2023). 

Analysis: 

Use the laguna shapefile to create sampling of “lagoon spectral signatures” and “not lagoon signatures” to train a deep learning model- random forest to recognize lagunas 

Use our trained model to identify lagunas in the Yucatán peninsula using the “municipalities” layer to set the spatial boundaries of our model, and focus on our three municipalities that Sitilpech, Uayalceh , and Kinchil are located in. 

We will start looping though the imagery from each year starting from 2019 and moving backwards to identify when CAFOS first starts appearing in the area. For each CAFO we will ideally be able to identify what year they started and at what rate they have grown since. 

Visualization: 

After identifying when they first appear, we will then use visualization techniques (maps and graphs) to track their growth over time. 

 

We would choose files from the latest date, to train our data on, for example, 2019. 

Train the data on earlier year and see how well it does. 

we would use google earth engine files from the same date that we know the shape files are from.


--------------------------------------------------------------------------------

3. Data: A brief (~250 words) description and visualization of the datasets you will be using. That means spatial plots of the main datasets and their key values, and, as a bonus, a plot of summary statistics, e.g. a histogram or boxplot of one of the more importants variables in the dataset.


We will be using the rgee package to access google earth engine data catalogue: https://developers.google.com/earth-engine/datasets/ 

We are also using data provided to us by Mike Cecil on previous Yucatán CAFOs research: https://storymaps.arcgis.com/collections/3e7203cf44cf417c9b5fe1db7a182293?item=1 

We will be mainly using the lagoons and município shapefile from the storymap project. The lagoons shapefile dates back to 2000. We will use imagery from landsat 5,7,8,9 for tracing the appearance of CAFOS back through time. The most recent lagoons from the shapefile are from 2019. We will use 2019 landsat imagery to train the random forest model. We may have to use earlier images to train the model for each landsat satellite. 

This github and tutorial video have been very helpful for learning how to use the rgee package: 

https://github.com/ricds/DL_RS_GEE 

Introduction to Google Earth Engine with R language 

Below we have included code for creating a vector object of the study area that we will use to train our classification model. Following that, we included code that extracts Landsat 8 images of the study area, applies a cloud mask, and compiles multiple dates into one to form a cloudless image of the state of Yucatán. The last few lines of code visualizes the study area.


Libraries needed for project:
```{r}
# Calling the project
library(cafos23)

# Project funtio ns:
  # Cloud mask for Landsat 8:  maskL8sr()
  # Cloud mask for Sentinel 2: maskS2clouds()


library(tidyverse)
library(sf)
library(rgee)
library(googleCloudStorageR)
library(mapview)
library(leaflet)


#Initialize google earth engine
ee_Initialize(user = 'adominguesclarku@gmail.com', drive = TRUE, gcs = TRUE)
```
Code for reading a shape file of Yucatán and making into a study area layer.

```{r}
# Import yucatan shape file. 
# Downloaded municipios Mexican 2021 map from government source: https://data.humdata.org/dataset/cod-ab-mex
yucatan <- st_read("../data/yucatan/yucatan_govmex_2021.shp") 

# Project to EPSG:32616 :  Projected CRS: WGS 84 / UTM zone 16N and make it just the state boundary
yucatan_pj <- st_transform(yucatan, 32616) %>% st_union()

#plot(yucatan[3])
# Study area for training classification model is the state of Yucatán: 
plot(yucatan_pj)

# Make the yucatan shapefile into an ee object
yucatan_ee <- yucatan_pj %>% st_geometry() %>% sf_as_ee(proj = "EPSG:32616")

# Create a Feature from the Geometry.
yucatan_feature <- ee$Feature(yucatan_ee)

```



In this chunk we extract Landsat 8 data from google earth engine for the entire year of 2019. Only images with less than 15% cloud cover are used. We then consolidate them taking the median of the pixel values in order to get a cloudless image.

```{r}

# Landsat 8 data: https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C02_T1_L2
L8sr_yucatan_2019 = ee$ImageCollection('LANDSAT/LC08/C02/T1_L2')$
  # Reproject to UTM zone 16N with a 30 meter scale
  map(function(image){image$reproject(crs = 'EPSG:32616', scale = 30)})$
  # filter for the Yucatán study area
  filterBounds(yucatan_feature$geometry())$
  map(function(image){ image$clip(yucatan_feature) })$
  # Select the date of year
  filterDate('2019-01-01', '2020-01-01')$
  # Pre-filter to get less cloudy granules. 15% cloud cover
  filter(ee$Filter$lt('CLOUD_COVER',15))$
  # mask clouds
  map(maskL8sr)

# print the metadata of the Landsat 8 image collection
#ee_print(L8sr_yucatan_2019)

# make composite image taking median pixel value
L8sr_yucatan_median = L8sr_yucatan_2019 $ median()

# Center and zoom the map on the study area
Map$centerObject(yucatan_feature, zoom = 8)

# Visualize our composite covering the whole area, with no clouds
Map$addLayer(eeObject = L8sr_yucatan_median,
             visParams = list(
               bands = c("SR_B4", "SR_B3", "SR_B2"),
               min = 0.0,
               max = 0.3
             ),
             name = 'RGB')

```



We tried the same thing with Sentinel 2 data in order to compare the two:

```{r}

# Sentinel-2 data
sentinel2_data_yucatan_median = ee$ImageCollection('COPERNICUS/S2_SR')$
  # filter for the Yucatán study area
  filterBounds(yucatan_feature$geometry())$
  map(function(image){ image$clip(yucatan_feature) })$
  # Select the date of year
  filterDate('2019-04-10', '2019-04-20')$
  # Pre-filter to get less cloudy granules.
  filter(ee$Filter$lt('CLOUDY_PIXEL_PERCENTAGE',10))$
  # mask clouds
  map(maskS2clouds)$
  # make composite image taking median pixel value
  median()

#Print metadata
#ee_print(sentinel2_data_yucatan_median)
  
# Set resolution and projection
s2_yucatan_res10 <- sentinel2_data_yucatan_median$setDefaultProjection(
  crs = "EPSG:32616", scale = 10
)



#Center map on study area
Map$centerObject(yucatan_feature, zoom = 8)

# Visualize our composite covering the whole area, with no clouds :)
Map$addLayer(eeObject = s2_yucatan_res10,
             visParams = list(
               bands = c("B4", "B3", "B2"),
               min = 0,
               max = 0.3       # spectral range of bands
             ),
             name = 'RGB')

```


Here I plot the CAFO lagoons over the landsat image. I also make a histogram of the lagoons per year. Most of the lagoons are from 2000, this is probably a misrepresentation. Lagoons were probably created earlier but data collection started at 2000. Tracking will have to go to before the year 2000.

```{r}

lagunas <- st_read("C:\\Rclass\\cafos23\\data\\lagunas\\lagunas.shp") 

# Project to EPSG:32616 :  Projected CRS: WGS 84 / UTM zone 16N, same as study are
lagunas_pj <- st_transform(lagunas, 32616) 

plot(yucatan_pj)                  # plot study area (state of Yucatán)
plot(lagunas_pj[1], add = TRUE)   # plot lagoons



# Make the yucatan shapefile into an ee object
lagunas_ee <- lagunas_pj %>% st_geometry() %>% sf_as_ee(proj = "EPSG:32616")

# Create a Feature Collection from the Geometry.
lagunas_fc <- ee$FeatureCollection(lagunas_ee)

# Print metadata of both layer
#ee_print(L8sr_yucatan_median)
#ee_print(lagunas_fc)


# set projection and resolution (currently redundant step)
ls8_yucatan_res30 = L8sr_yucatan_median$setDefaultProjection(
  crs = "EPSG:32616", scale = 30
)



# Center and zoom the map on the study area
Map$centerObject(yucatan_feature, zoom = 8)


# Visualize our composite covering the whole area, with no clouds
Map$addLayer(eeObject = ls8_yucatan_res30,
             visParams = list(
               bands = c("SR_B4", "SR_B3", "SR_B2"),
               min = 0.0,
               max = 0.3
             ),
             name = 'Yucatan_RGB') +
# Visualize the lagoons over the landsat image
  Map$addLayer(eeObject = lagunas_fc,
               visParams = list(
                 color = "turquoise"),
               name = "Lagunas",
               opacity = 0.25
               )


# Plot number of lagoons per Year
lagunas_df <- as.data.frame(lagunas_pj)
lagunas_count <- lagunas_df %>% 
  group_by(Year) %>% 
  summarize(n_lagunas = n())

ggplot(lagunas_count, aes(x=Year, y=n_lagunas)) +
  geom_bar(stat="identity", fill="steelblue") +
  labs(x="Year", y="Number of Lagoons", title="Number of Lagoons Created per Year")


```


Plotted lagoons on sentinel data to see if resolution is better:

```{r}


#Center map on study area
Map$centerObject(yucatan_feature, zoom = 8)

# Visualize our composite covering the whole area, with no clouds :)
Map$addLayer(eeObject = s2_yucatan_res10,
             visParams = list(
               bands = c("B4", "B3", "B2"),
               min = 0,
               max = 0.3       # spectral range of bands
             ),
             name = 's2_RGB') +
# Visualize the lagoons over the landsat image
  Map$addLayer(eeObject = lagunas_fc,
               visParams = list(
                 color = "turquoise"),
               name = "Lagunas",
                opacity = 0.5
               )


```


--------------------------------------------------------------------------------

4. Code: A bullet point summary of the analysis and coding approach that you propose to follow. For teams, this section should include a description of which member will be responsible for each bullet point.


-  Using rgee to get the Landsat images - André 

André will focus on writing the code that extracts from Google Earth Engine the landsat images we need for the analysis. This includes finding cloudless images for the entire time series and cropping them to the study areas. 

- Sample lagoon shape file and create study area shape files – Clio 

Clio will work on writing the code for sampling the lagoon shape file. She will also use the município shape file to identify the study area of the three communities and sample points from these areas that are not lagoons. 

- Train random forest model – Clio 

Clio will confirm that the lagoons used in the sample points correspond with the existing lagoons in the satellite image used for training the model. She will use the sample points on a random forest model to conduct a binary classification that relates landsat bands with spectral indexes to identify the signature of CAFO lagoons. 

- Run random forest on time series – André 

André will test the model on an image from a different date to see if it can identify the lagoons. He will then work on applying the model to the entire span of the time series and identify when the lagoons begin to appear. This will be reproduced for each of the three study areas. 

- Code for presenting maps and plots. - Both of us, divide between plots and maps 

André and Clio will work together to create visualization of the results that map the CAFO lagoons and graph their expansion. 

 
 
--------------------------------------------------------------------------------



5. Timelines: Provide a timeline for when each portion of the analysis will be completed. These timelines should be constructed relative to the time period of presentations (during the last two weeks of class) and final project submission (during exam week). For teams, names should be associated with each step on the timeline.


Timeline: 

April 17th –24th: 

-Get our data/imagery 

-Get a satellite image for each year starting in 2019, until 1995(five years before our data begins) 

-Check which lagoons are present in 2019 image 

-By the end of this week sub-section of “processing” in methods should be completed 

April 24th – 30th: 

-Random sampling of lagunas 

-Train our random forest model 

-Run the model 

-Identify years where CAFOS start and identify which ones have seen the most growth 

-By the end of this week sub-section of “analysis” in methods should be completed  

May 1-6th:  

-Create visualizations and outputs 

-By the end of this week, our project will be complete and ready for submission 


--------------------------------------------------------------------------------


6. Anticipated outcomes: Briefly describe, as bullet points, the outcomes you expect for each of your primary project objectives

- Our goal is to develop a classification model for identifying CAFO locations, and use historical remote sensing imagery to estimate when CAFO’s were built. 

- We expect to determine around what years CAFOs started appearing in the Yucatán communities of Sitilpech, Uayalceh , and Kinchil. 

- We expect to able to track the growth of CAFOS in these communities through time to the present. 

- We may find patterns in the appearance, distribution, and / or growth rate of the CAFOs in each study area. 

- We hope to get plenty of practice with using Google Earth Engine in R. 
